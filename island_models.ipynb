{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import csv\n",
    "from PIL import Image\n",
    "import glob\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import tr_label\n",
    "tr_label_file = './data_island_in_the_sun/labels_training.csv'\n",
    "tr_label = open(tr_label_file, 'rt')\n",
    "tr_read = csv.reader(tr_label, delimiter=',', quoting=csv.QUOTE_NONE)\n",
    "tr_label_list = list(tr_read)\n",
    "y_data = np.array(tr_label_list)[1:].astype('int')\n",
    "#print(y_data)\n",
    "y_list = y_data[:,1:]\n",
    "\n",
    "num_data = y_list.shape[0]\n",
    "\n",
    "y_ = np.zeros([num_data,2])\n",
    "\n",
    "for i in range(num_data):\n",
    "    y_[i,y_list[i][0]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import images\n",
    "filelist = [\"\" for x in range(1500)]\n",
    "\n",
    "for i in range(0, 1500):\n",
    "    path = \"./data_island_in_the_sun/train_data/\" + str(i) + \".tif\"\n",
    "    filelist[i] = path\n",
    "\n",
    "x_data = np.array([np.array(Image.open(fname)) for fname in filelist])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 101, 101, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prepocess \n",
    "x_list = x_data\n",
    "x_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x_list, y_, test_size=0.2, random_state=0)\n",
    "# X_train.shape, y_train.shape\n",
    "# X_test.shape, y_test.shape\n",
    "\n",
    "num_train = X_train.shape[0]\n",
    "num_valid = X_test.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "learning_rate = 0.00001\n",
    "num_epochs = 900\n",
    "batch_size = 100\n",
    "display_step = 100\n",
    "img_width = 101\n",
    "\n",
    "\n",
    "# Network Parameters\n",
    "num_input = img_width*img_width*3 # data input (img shape: 101 * 101 * 3)\n",
    "num_classes = 2 # total classes (0/1)\n",
    "dropout = 0.75 # Dropout, probability to keep units\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tf Graph input\n",
    "X = tf.placeholder(tf.float32, [None, img_width,img_width,3])\n",
    "Y = tf.placeholder(tf.float32, [None, num_classes])\n",
    "keep_prob = tf.placeholder(tf.float32) # dropout (keep probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create some wrappers for simplicity\n",
    "def conv2d(x, W, b, strides=1):\n",
    "    # Conv2D wrapper, with bias and relu activation\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "def maxpool2d(x, k=2):\n",
    "    # MaxPool2D wrapper\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],\n",
    "                          padding='SAME')\n",
    "\n",
    "\n",
    "# Create model\n",
    "def conv_net(x, weights, biases, dropout):\n",
    "    # Tensor input become 4-D: [Batch Size, Height, Width, Channel]\n",
    "    \n",
    "    # x = tf.reshape(x, shape=[-1, img_width, img_width, 3])\n",
    "\n",
    "    # Convolution Layer\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "    # Max Pooling (down-sampling)\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "\n",
    "    # Convolution Layer\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    # Max Pooling (down-sampling)\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "\n",
    "    # Fully connected layer\n",
    "    # Reshape conv2 output to fit fully connected layer input\n",
    "    fc1 = tf.contrib.layers.flatten(conv2)\n",
    "    # fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    # Apply Dropout\n",
    "    fc1 = tf.nn.dropout(fc1, dropout)\n",
    "\n",
    "    # Output, class prediction\n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    # 5x5 conv, 1 input, 32 outputs\n",
    "    'wc1': tf.Variable(tf.random_normal([5, 5, 3, 32])),\n",
    "    # 5x5 conv, 32 inputs, 64 outputs\n",
    "    'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n",
    "    # fully connected, 7*7*64 inputs, 1024 outputs\n",
    "    'wd1': tf.Variable(tf.random_normal([676*64, 1024])),\n",
    "    # 1024 inputs, 10 outputs (class prediction)\n",
    "    'out': tf.Variable(tf.random_normal([1024, num_classes]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.random_normal([32])),\n",
    "    'bc2': tf.Variable(tf.random_normal([64])),\n",
    "    'bd1': tf.Variable(tf.random_normal([1024])),\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}\n",
    "\n",
    "# Construct model\n",
    "logits = conv_net(X, weights, biases, keep_prob)\n",
    "prediction = tf.nn.softmax(logits)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0, Minibatch Loss= 51546320.0000, Training Accuracy= 0.350\n",
      "('Testing Accuracy:', 0.36666664)\n",
      "Step 100, Minibatch Loss= 15040747.0000, Training Accuracy= 0.650\n",
      "('Testing Accuracy:', 0.58999997)\n",
      "Step 200, Minibatch Loss= 18376028.0000, Training Accuracy= 0.560\n",
      "('Testing Accuracy:', 0.60666668)\n",
      "Step 300, Minibatch Loss= 16259370.0000, Training Accuracy= 0.650\n",
      "('Testing Accuracy:', 0.60666668)\n",
      "Step 400, Minibatch Loss= 12838532.0000, Training Accuracy= 0.700\n",
      "('Testing Accuracy:', 0.60666668)\n",
      "Step 500, Minibatch Loss= 13901176.0000, Training Accuracy= 0.580\n",
      "('Testing Accuracy:', 0.61000001)\n",
      "Step 600, Minibatch Loss= 13909667.0000, Training Accuracy= 0.680\n",
      "('Testing Accuracy:', 0.62)\n",
      "Step 700, Minibatch Loss= 10060928.0000, Training Accuracy= 0.700\n",
      "('Testing Accuracy:', 0.61666667)\n",
      "Step 800, Minibatch Loss= 13434760.0000, Training Accuracy= 0.600\n",
      "('Testing Accuracy:', 0.62333333)\n",
      "Step 900, Minibatch Loss= 11719424.0000, Training Accuracy= 0.710\n",
      "('Testing Accuracy:', 0.62333333)\n",
      "Step 1000, Minibatch Loss= 9538932.0000, Training Accuracy= 0.730\n",
      "('Testing Accuracy:', 0.62666667)\n",
      "Step 1100, Minibatch Loss= 11097808.0000, Training Accuracy= 0.620\n",
      "('Testing Accuracy:', 0.63333333)\n",
      "Step 1200, Minibatch Loss= 8443348.0000, Training Accuracy= 0.730\n",
      "('Testing Accuracy:', 0.62666667)\n",
      "Step 1300, Minibatch Loss= 7794953.0000, Training Accuracy= 0.730\n",
      "('Testing Accuracy:', 0.62333333)\n",
      "Step 1400, Minibatch Loss= 8738881.0000, Training Accuracy= 0.620\n",
      "('Testing Accuracy:', 0.62666667)\n",
      "Step 1500, Minibatch Loss= 8393503.0000, Training Accuracy= 0.740\n",
      "('Testing Accuracy:', 0.63666666)\n",
      "Step 1600, Minibatch Loss= 7448312.0000, Training Accuracy= 0.760\n",
      "('Testing Accuracy:', 0.64000005)\n",
      "Step 1700, Minibatch Loss= 7170488.5000, Training Accuracy= 0.670\n",
      "('Testing Accuracy:', 0.64666671)\n",
      "Step 1800, Minibatch Loss= 8132433.0000, Training Accuracy= 0.750\n",
      "('Testing Accuracy:', 0.65333331)\n",
      "Step 1900, Minibatch Loss= 6038442.0000, Training Accuracy= 0.780\n",
      "('Testing Accuracy:', 0.66666669)\n",
      "Step 2000, Minibatch Loss= 7019858.0000, Training Accuracy= 0.650\n",
      "('Testing Accuracy:', 0.67333335)\n",
      "Step 2100, Minibatch Loss= 5237904.0000, Training Accuracy= 0.760\n",
      "('Testing Accuracy:', 0.66333336)\n",
      "Step 2200, Minibatch Loss= 5657836.5000, Training Accuracy= 0.790\n",
      "('Testing Accuracy:', 0.67000002)\n",
      "Step 2300, Minibatch Loss= 5435518.5000, Training Accuracy= 0.730\n",
      "('Testing Accuracy:', 0.67333335)\n",
      "Step 2400, Minibatch Loss= 4029879.5000, Training Accuracy= 0.740\n",
      "('Testing Accuracy:', 0.67666668)\n",
      "Step 2500, Minibatch Loss= 4844096.0000, Training Accuracy= 0.800\n",
      "('Testing Accuracy:', 0.67666668)\n",
      "Step 2600, Minibatch Loss= 5407618.5000, Training Accuracy= 0.720\n",
      "('Testing Accuracy:', 0.69)\n",
      "Step 2700, Minibatch Loss= 4368777.0000, Training Accuracy= 0.760\n",
      "('Testing Accuracy:', 0.68333334)\n",
      "Step 2800, Minibatch Loss= 4677955.5000, Training Accuracy= 0.820\n",
      "('Testing Accuracy:', 0.69333333)\n",
      "Step 2900, Minibatch Loss= 4530982.0000, Training Accuracy= 0.770\n",
      "('Testing Accuracy:', 0.69333333)\n",
      "Step 3000, Minibatch Loss= 3838134.2500, Training Accuracy= 0.770\n",
      "('Testing Accuracy:', 0.69333333)\n",
      "Step 3100, Minibatch Loss= 3893572.0000, Training Accuracy= 0.790\n",
      "('Testing Accuracy:', 0.69)\n",
      "Step 3200, Minibatch Loss= 3950273.0000, Training Accuracy= 0.790\n",
      "('Testing Accuracy:', 0.70666665)\n",
      "Step 3300, Minibatch Loss= 3054462.0000, Training Accuracy= 0.790\n",
      "('Testing Accuracy:', 0.69999999)\n",
      "Step 3400, Minibatch Loss= 3478049.2500, Training Accuracy= 0.800\n",
      "('Testing Accuracy:', 0.69999999)\n",
      "Step 3500, Minibatch Loss= 3603659.0000, Training Accuracy= 0.790\n",
      "('Testing Accuracy:', 0.69999999)\n",
      "Step 3600, Minibatch Loss= 2812465.2500, Training Accuracy= 0.790\n",
      "('Testing Accuracy:', 0.69999999)\n",
      "Step 3700, Minibatch Loss= 3196342.0000, Training Accuracy= 0.810\n",
      "('Testing Accuracy:', 0.70999998)\n",
      "Step 3800, Minibatch Loss= 3085158.0000, Training Accuracy= 0.810\n",
      "('Testing Accuracy:', 0.71666664)\n",
      "Step 3900, Minibatch Loss= 2385272.5000, Training Accuracy= 0.800\n",
      "('Testing Accuracy:', 0.71333331)\n",
      "Step 4000, Minibatch Loss= 2635584.0000, Training Accuracy= 0.830\n",
      "('Testing Accuracy:', 0.70333332)\n",
      "Step 4100, Minibatch Loss= 2552409.5000, Training Accuracy= 0.860\n",
      "('Testing Accuracy:', 0.70666665)\n",
      "Step 4200, Minibatch Loss= 1929255.8750, Training Accuracy= 0.840\n",
      "('Testing Accuracy:', 0.70666665)\n",
      "Step 4300, Minibatch Loss= 2381851.7500, Training Accuracy= 0.840\n",
      "('Testing Accuracy:', 0.70333332)\n",
      "Step 4400, Minibatch Loss= 2162118.0000, Training Accuracy= 0.850\n",
      "('Testing Accuracy:', 0.70666665)\n",
      "Step 4500, Minibatch Loss= 1918079.7500, Training Accuracy= 0.850\n",
      "('Testing Accuracy:', 0.70999998)\n",
      "Step 4600, Minibatch Loss= 2000456.0000, Training Accuracy= 0.810\n",
      "('Testing Accuracy:', 0.69666666)\n",
      "Step 4700, Minibatch Loss= 1755869.7500, Training Accuracy= 0.870\n",
      "('Testing Accuracy:', 0.70999998)\n",
      "Step 4800, Minibatch Loss= 1527723.6250, Training Accuracy= 0.890\n",
      "('Testing Accuracy:', 0.69999999)\n",
      "Step 4900, Minibatch Loss= 1735013.0000, Training Accuracy= 0.830\n",
      "('Testing Accuracy:', 0.70999998)\n",
      "Step 5000, Minibatch Loss= 1539347.7500, Training Accuracy= 0.870\n",
      "('Testing Accuracy:', 0.70333332)\n",
      "Step 5100, Minibatch Loss= 1377765.6250, Training Accuracy= 0.880\n",
      "('Testing Accuracy:', 0.71999997)\n",
      "Step 5200, Minibatch Loss= 1449475.0000, Training Accuracy= 0.840\n",
      "('Testing Accuracy:', 0.71666664)\n",
      "Step 5300, Minibatch Loss= 1238373.5000, Training Accuracy= 0.880\n",
      "('Testing Accuracy:', 0.71333337)\n",
      "Step 5400, Minibatch Loss= 1176947.6250, Training Accuracy= 0.890\n",
      "('Testing Accuracy:', 0.71333331)\n",
      "Step 5500, Minibatch Loss= 1286223.6250, Training Accuracy= 0.840\n",
      "('Testing Accuracy:', 0.71333331)\n",
      "Step 5600, Minibatch Loss= 1015191.9375, Training Accuracy= 0.870\n",
      "('Testing Accuracy:', 0.71333337)\n",
      "Step 5700, Minibatch Loss= 931705.5000, Training Accuracy= 0.910\n",
      "('Testing Accuracy:', 0.71666664)\n",
      "Step 5800, Minibatch Loss= 1163428.0000, Training Accuracy= 0.850\n",
      "('Testing Accuracy:', 0.71999997)\n",
      "Step 5900, Minibatch Loss= 789666.3750, Training Accuracy= 0.890\n",
      "('Testing Accuracy:', 0.71999997)\n",
      "Step 6000, Minibatch Loss= 794075.8125, Training Accuracy= 0.910\n",
      "('Testing Accuracy:', 0.71333337)\n",
      "Step 6100, Minibatch Loss= 1026154.6875, Training Accuracy= 0.870\n",
      "('Testing Accuracy:', 0.72999996)\n",
      "Step 6200, Minibatch Loss= 658958.0000, Training Accuracy= 0.910\n",
      "('Testing Accuracy:', 0.71666664)\n",
      "Step 6300, Minibatch Loss= 631867.6250, Training Accuracy= 0.920\n",
      "('Testing Accuracy:', 0.72000003)\n",
      "Step 6400, Minibatch Loss= 942796.0625, Training Accuracy= 0.890\n",
      "('Testing Accuracy:', 0.72666663)\n",
      "Step 6500, Minibatch Loss= 450794.6250, Training Accuracy= 0.910\n",
      "('Testing Accuracy:', 0.72666669)\n",
      "Step 6600, Minibatch Loss= 599387.1875, Training Accuracy= 0.920\n",
      "('Testing Accuracy:', 0.72333336)\n",
      "Step 6700, Minibatch Loss= 797319.1250, Training Accuracy= 0.910\n",
      "('Testing Accuracy:', 0.7233333)\n",
      "Step 6800, Minibatch Loss= 288665.4375, Training Accuracy= 0.930\n",
      "('Testing Accuracy:', 0.72666669)\n",
      "Step 6900, Minibatch Loss= 698762.1250, Training Accuracy= 0.890\n",
      "('Testing Accuracy:', 0.72666663)\n",
      "Step 7000, Minibatch Loss= 692764.3750, Training Accuracy= 0.930\n",
      "('Testing Accuracy:', 0.7166667)\n",
      "Step 7100, Minibatch Loss= 203177.5312, Training Accuracy= 0.950\n",
      "('Testing Accuracy:', 0.70999998)\n",
      "Step 7200, Minibatch Loss= 558957.5625, Training Accuracy= 0.900\n",
      "('Testing Accuracy:', 0.71666664)\n",
      "Step 7300, Minibatch Loss= 579477.8750, Training Accuracy= 0.930\n",
      "('Testing Accuracy:', 0.71000004)\n",
      "Step 7400, Minibatch Loss= 257049.7188, Training Accuracy= 0.920\n",
      "('Testing Accuracy:', 0.71666664)\n",
      "Step 7500, Minibatch Loss= 473668.5938, Training Accuracy= 0.910\n",
      "('Testing Accuracy:', 0.71666664)\n",
      "Step 7600, Minibatch Loss= 544783.8750, Training Accuracy= 0.940\n",
      "('Testing Accuracy:', 0.72333336)\n",
      "Step 7700, Minibatch Loss= 218644.3281, Training Accuracy= 0.930\n",
      "('Testing Accuracy:', 0.71666664)\n",
      "Step 7800, Minibatch Loss= 405414.7812, Training Accuracy= 0.920\n",
      "('Testing Accuracy:', 0.71999997)\n",
      "Step 7900, Minibatch Loss= 510149.1875, Training Accuracy= 0.940\n",
      "('Testing Accuracy:', 0.7233333)\n",
      "Step 8000, Minibatch Loss= 186537.0000, Training Accuracy= 0.940\n",
      "('Testing Accuracy:', 0.7233333)\n",
      "Step 8100, Minibatch Loss= 309836.0938, Training Accuracy= 0.930\n",
      "('Testing Accuracy:', 0.71666664)\n",
      "Step 8200, Minibatch Loss= 492330.6875, Training Accuracy= 0.940\n",
      "('Testing Accuracy:', 0.71999997)\n",
      "Step 8300, Minibatch Loss= 180265.2656, Training Accuracy= 0.940\n",
      "('Testing Accuracy:', 0.71999997)\n",
      "Step 8400, Minibatch Loss= 272260.6250, Training Accuracy= 0.930\n",
      "('Testing Accuracy:', 0.71333331)\n",
      "Step 8500, Minibatch Loss= 426533.2500, Training Accuracy= 0.940\n",
      "('Testing Accuracy:', 0.72000003)\n",
      "Step 8600, Minibatch Loss= 96727.7969, Training Accuracy= 0.960\n",
      "('Testing Accuracy:', 0.71333331)\n",
      "Step 8700, Minibatch Loss= 200498.9844, Training Accuracy= 0.940\n",
      "('Testing Accuracy:', 0.72333336)\n",
      "Step 8800, Minibatch Loss= 419766.2812, Training Accuracy= 0.940\n",
      "('Testing Accuracy:', 0.71999997)\n",
      "Step 8900, Minibatch Loss= 115393.5938, Training Accuracy= 0.950\n",
      "('Testing Accuracy:', 0.70999998)\n",
      "Step 9000, Minibatch Loss= 227495.1562, Training Accuracy= 0.950\n",
      "('Testing Accuracy:', 0.71999997)\n",
      "Step 9100, Minibatch Loss= 315439.9062, Training Accuracy= 0.960\n",
      "('Testing Accuracy:', 0.71666664)\n",
      "Step 9200, Minibatch Loss= 59450.1406, Training Accuracy= 0.960\n",
      "('Testing Accuracy:', 0.71666664)\n",
      "Step 9300, Minibatch Loss= 148182.9375, Training Accuracy= 0.950\n",
      "('Testing Accuracy:', 0.70666665)\n",
      "Step 9400, Minibatch Loss= 276252.6562, Training Accuracy= 0.940\n",
      "('Testing Accuracy:', 0.71333331)\n",
      "Step 9500, Minibatch Loss= 64998.3281, Training Accuracy= 0.970\n",
      "('Testing Accuracy:', 0.72000003)\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "\n",
    "    num_st = num_train/batch_size\n",
    "    \n",
    "    for i in range(num_epochs):\n",
    "        for step in range(num_st):\n",
    "            si,ei = step*batch_size,(step+1)*batch_size \n",
    "            batch_x, batch_y = X_train[si:ei ,:], y_train[si:ei,:]\n",
    "            # Run optimization op (backprop)\n",
    "            sess.run(train_op, feed_dict={X: batch_x, Y: batch_y, keep_prob: dropout})\n",
    "            if (i*num_st+step) % display_step == 0:\n",
    "                # Calculate batch loss and accuracy\n",
    "                loss, acc = sess.run([loss_op, accuracy], feed_dict={X: batch_x,\n",
    "                                                                     Y: batch_y,\n",
    "                                                                     keep_prob: 1.0})\n",
    "                print(\"Step \" + str(i*num_st+step) + \", Minibatch Loss= \" + \\\n",
    "                      \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                      \"{:.3f}\".format(acc))\n",
    "\n",
    "                print(\"Testing Accuracy:\", \\\n",
    "                    sess.run(accuracy, feed_dict={X: X_test,\n",
    "                                                  Y: y_test,\n",
    "                                                  keep_prob: 1.0}))                \n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Calculate accuracy for 256 MNIST test images\n",
    "    print(\"Testing Accuracy:\", \\\n",
    "        sess.run(accuracy, feed_dict={X: X_test,\n",
    "                                      Y: y_test,\n",
    "                                      keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 101, 101, 3)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 2)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python2",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
